{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a *linear model*, e.g. a model that assumes a linear relationship between the input variables (x) and the single output variable (y). More specifically, that y can be calculated from a linear combination of the input variables (x).\n",
    "\n",
    "Why are we learning linear regression?\n",
    "- widely used\n",
    "- runs fast\n",
    "- easy to use (not a lot of tuning required)\n",
    "- highly interpretable\n",
    "- basis for many other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T11:36:31.073943Z",
     "start_time": "2020-10-08T11:34:06.155794Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:54:11.160012Z",
     "start_time": "2020-10-05T06:54:10.847680Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Advertising.csv')\n",
    "df = df[df.columns[1:]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the **features**?\n",
    "- TV: advertising dollars spent on TV for a single product in a given market (in thousands of dollars)\n",
    "- Radio: advertising dollars spent on Radio\n",
    "- Newspaper: advertising dollars spent on Newspaper\n",
    "\n",
    "What is the **response**?\n",
    "- Sales: sales of a single product in a given market (in thousands of sales units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:44:47.279882Z",
     "start_time": "2020-06-01T11:44:47.268889Z"
    }
   },
   "outputs": [],
   "source": [
    "#How many points are in the dataset?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Plotting Distributions\n",
    "It is good practice to check the distribution of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:45:01.999605Z",
     "start_time": "2020-06-01T11:44:58.691005Z"
    }
   },
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a relationship between advertising type and the product sales? Scatterplots could help to visualize possible linear relationships as first pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:46:23.771802Z",
     "start_time": "2020-06-01T11:46:20.598357Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 8), sharey=True)\n",
    "df.plot(kind='scatter', x='TV', y='Sales', ax=axs[0], grid=True)\n",
    "df.plot(kind='scatter', x='Radio', y='Sales', ax=axs[1], grid=True)\n",
    "df.plot(kind='scatter', x='Newspaper', y='Sales', ax=axs[2], grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simple Linear Regression\n",
    "\n",
    "Simple linear regression is an approach for predicting a **quantitative response** using a **single feature** (or \"predictor\" or \"input variable\"). It takes the following form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "What does each term represent?\n",
    "- $y$ is the response\n",
    "- $x$ is the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "\n",
    "Together, $\\beta_0$ and $\\beta_1$ are called the **model coefficients**. To create your model, you must \"learn\" the values of these coefficients. And once we've learned these coefficients, we can use the model to predict Sales!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:50:58.315885Z",
     "start_time": "2020-05-24T14:50:58.295898Z"
    }
   },
   "source": [
    "### 3. Estimating (\"Learning\") Model Coefficients\n",
    "\n",
    "Generally speaking, coefficients are estimated using the **least squares criterion**, which means we are find the line (mathematically) which minimizes the **sum of squared residuals** (or \"sum of squared errors\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:50:52.565312Z",
     "start_time": "2020-05-24T14:50:52.547324Z"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/justmarkham/DAT4/master/notebooks/08_estimating_coefficients.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What elements are present in the diagram?\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the distances between the observed values and the least squares line.\n",
    "\n",
    "How do the model coefficients relate to the least squares line?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://raw.githubusercontent.com/justmarkham/DAT4/master/notebooks/08_slope_intercept.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\beta_0$ is the **intercept** (the value of $y$ when $x$=0)\n",
    "- $\\beta_1$ is the **slope** (the change in $y$ divided by change in $x$)\n",
    "\n",
    "\n",
    "We use sklearn's `linear_model` module to get $\\beta_0$ and $\\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:48:39.984862Z",
     "start_time": "2020-06-01T11:48:35.735173Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(df['TV'].values.reshape(-1,1), df['Sales'].values.reshape(-1,1))\n",
    "\n",
    "print('Model slope: %0.4f' % model.coef_[0])\n",
    "print('Model intercept: %0.4f' % model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Interpreting Model Coefficients\n",
    "\n",
    "How do we interpret the TV coefficient ($\\beta_1$)?\n",
    "- A \"unit\" increase in TV ad spending is **associated with** a 0.0475 \"unit\" increase in Sales.\n",
    "- Or more clearly: An additional $1,000 spent on TV ads is **associated with** an increase in sales of 47.5 sales units.\n",
    "\n",
    "Note that if an increase in TV ad spending was associated with a **decrease** in sales, $\\beta_1$ would be **negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using the Model for Prediction\n",
    "\n",
    "Let's say that there was a new market where the TV advertising spend was **$50,000**. What would we predict for the Sales in that market?\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "$$y = 7.0326 + 0.0475 \\times 50$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:50:24.272006Z",
     "start_time": "2020-06-01T11:50:24.257014Z"
    }
   },
   "outputs": [],
   "source": [
    "# manually calculate the prediction\n",
    "7.0326 + 0.0475*50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plotting the Least Squares Line\n",
    "\n",
    "Let's make predictions for the **smallest and largest observed values of x**, and then use the predicted values to plot the least squares line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:51:22.127839Z",
     "start_time": "2020-06-01T11:51:22.076868Z"
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for min and max x and store them\n",
    "x_lsl = [[df['TV'].min()],[df['TV'].max()]]\n",
    "y_lsl = model.predict(x_lsl)\n",
    "y_lsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:51:29.241468Z",
     "start_time": "2020-06-01T11:51:28.066665Z"
    }
   },
   "outputs": [],
   "source": [
    "# first, plot the observed data\n",
    "df.plot(kind='scatter', x='TV', y='Sales')\n",
    "\n",
    "# then, plot the least squares line\n",
    "plt.plot(x_lsl, y_lsl, c='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model fit performance\n",
    "\n",
    "The most common way to evaluate the overall fit of a linear model is by the **R-squared** value. R-squared is the **proportion of variance explained**, meaning the proportion of variance in the observed data that is explained by the model, or the reduction in error over the **null model**. (The null model just predicts the mean of the observed response, and thus it has an intercept and no slope.)\n",
    "\n",
    "R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model. Here's an example of what R-squared \"looks like\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:52:13.394123Z",
     "start_time": "2020-06-01T11:52:13.331170Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the R-squared\n",
    "model.score(df['TV'].values.reshape(-1,1), df['Sales'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that a \"good\" R-squared value? It's hard to say. The threshold for a good R-squared value depends widely on the domain. \n",
    "\n",
    "To check, we could calculate for the root-mean-squared error of the model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:53:06.232722Z",
     "start_time": "2020-06-01T11:53:06.208738Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def RMSE(model, X, y):\n",
    "    predicted = model.predict(X)\n",
    "    rmse = (np.sqrt(mean_squared_error(y, predicted)))\n",
    "    print('RMSE is {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:53:10.307756Z",
     "start_time": "2020-06-01T11:53:10.280773Z"
    }
   },
   "outputs": [],
   "source": [
    "RMSE(model, df['TV'].values.reshape(-1,1), df['Sales'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Visualizing Residuals and Checking for Skedasticity\n",
    "\n",
    "An important assumption of linear regression models is that the variance of the errors, i.e. the difference of the actual to the fitted response, should be *consistent* for all observations. In other words, the variance does not change for each observation or for a range of observations. This preferred condition is known as **homoscedasticity** (same scatter). If the variance changes, we refer to that as **heteroscedasticity** (different scatter).\n",
    "\n",
    "The easiest way to check this assumption is to create a residuals versus fitted value plot. On this type of graph, heteroscedasticity appears as a cone shape where the spread of the residuals increases in one direction. \n",
    "\n",
    "While heteroscedasticity does not cause bias in the coefficient estimates, it does make them less precise. \n",
    "Lower precision increases the likelihood that the coefficient estimates are further from the correct population value.\n",
    "Heteroscedasticity also tends to produce p-values that are smaller than they should be. This effect occurs because heteroscedasticity increases the variance of the coefficient estimates but the least-squares procedure does not detect this increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:54:16.927572Z",
     "start_time": "2020-06-01T11:54:14.362356Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute residuals\n",
    "x_actual = df['TV'].values.reshape(-1,1)\n",
    "y_actual = df['Sales'].values.reshape(-1,1)\n",
    "residuals = y_actual  - model.predict(x_actual)\n",
    "\n",
    "plt.scatter(y_actual, residuals)\n",
    "plt.axhline(0,color='k',ls='--')\n",
    "plt.xlabel('fitted response')\n",
    "plt.ylabel('residual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the errors are heteroskedastic. This means that the model could Based on the fitted response, low sales (<10 sales units) tend to be underestimated, high sales (>20 sales units) are overestimated, and a large spread occurs in the midrange. \n",
    "\n",
    "The causes for heteroscedasticity vary widely by subject-area. If you detect heteroscedasticity in your model, you’ll need to use your knowlege od the data to understand why it occurs. How can we improve this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Detecting Outliers\n",
    "We could improve the model by removing outliers. A simple approach is done using the interquartile range (IQR = 75th percentile - 25th percentile). Outliers in this case are defined as the observations that are below (Q1 − 1.5IQR)  or above (Q3 + 1.5IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:56:56.456899Z",
     "start_time": "2020-06-01T11:56:56.416921Z"
    }
   },
   "outputs": [],
   "source": [
    "q1 = df['Sales'].quantile(0.25)\n",
    "q3 =  df['Sales'].quantile(0.75)\n",
    "IQR = q3 -q1\n",
    "\n",
    "outliers = df[(df['Sales']<(q1-1.5*IQR))&(df['Sales']>(q3+1.5*IQR))]['Sales']\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the IQR criteria, there are no outliers in the Sales data-- all values are within acceptable variance. \n",
    "Thus we accept the fit as its best possible value for now and continue with hypothesis testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Hypothesis Testing and p-values\n",
    "\n",
    "Closely related to confidence intervals is **hypothesis testing**. Generally speaking, you start with a **null hypothesis** and an **alternative hypothesis** (that is opposite the null). Then, you check whether the data supports **rejecting the null hypothesis** or **failing to reject the null hypothesis**.\n",
    "\n",
    "(Note that \"failing to reject\" the null is not the same as \"accepting\" the null hypothesis. The alternative hypothesis may indeed be true, except that you just don't have enough data to show that.)\n",
    "\n",
    "As it relates to model coefficients, here is the conventional hypothesis test:\n",
    "- **null hypothesis:** There is no relationship between TV ads and Sales (and thus $\\beta_1$ equals zero)\n",
    "- **alternative hypothesis:** There is a relationship between TV ads and Sales (and thus $\\beta_1$ is not equal to zero)\n",
    "\n",
    "How do we test this hypothesis? Intuitively, we reject the null (and thus believe the alternative) if the **p-value** is near zero: usually its set to a very small number.\n",
    "\n",
    "sklearn doesnt have a native p-value method. we use the library `statsmodels` to calculate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T11:57:40.081460Z",
     "start_time": "2020-06-01T11:57:36.973738Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the p-values for the model coefficients\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# create a fitted model in one line\n",
    "model_stats = smf.ols(formula='Sales ~ TV', data=df).fit()\n",
    "model_stats.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A p-value less than 0.05 is one way to decide whether there is likely a relationship between the feature and the response. (Again, using 0.05 as the cutoff is just a convention.)\n",
    "\n",
    "In this case, the p-value for TV is far less than 0.05, thus points to a strong evidence of a (linear) relationship between TV ads and Sales. To be more accurate, p<0.05 means that the probability of detection of a linear trend between TV and Sales in a random set of points is less than 5%.\n",
    "\n",
    "Note that we generally ignore the p-value for the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seatwork\n",
    "Generate linear models relating each of the remaining features \"Radio\" and \"Newspaper\" to the response \"Sales\".\n",
    "Output the (a) model coefficients, (b) R-squared values, (c) RMSE and (d) plot the least squares line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T16:56:11.090602Z",
     "start_time": "2020-05-24T16:56:11.078608Z"
    }
   },
   "outputs": [],
   "source": [
    "# code for Radio- Sales here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T16:56:11.335463Z",
     "start_time": "2020-05-24T16:56:11.325469Z"
    }
   },
   "outputs": [],
   "source": [
    "# code for Newspaper - Sales here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Simple linear regression can easily be extended to include multiple features. This is called **multiple linear regression**:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "Each $x$ represents a different feature, and each feature has its own coefficient. In this case:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times Radio + \\beta_3 \\times Newspaper$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:00:30.914188Z",
     "start_time": "2020-06-01T12:00:30.656333Z"
    }
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper']\n",
    "X = df[feature_cols]\n",
    "y = df['Sales']\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "# print intercept and coefficients\n",
    "print(lm.intercept_)\n",
    "# pair the feature names with the coefficients\n",
    "print(list(zip(feature_cols, lm.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret these coefficients? For a given amount of Radio and Newspaper ad spending, an **increase of $1000 in TV ad spending** is associated with an **increase in Sales of 45.765 Sales units**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:01:47.376788Z",
     "start_time": "2020-06-01T12:01:47.361793Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the R-squared\n",
    "lm.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:02:02.720373Z",
     "start_time": "2020-06-01T12:02:02.705378Z"
    }
   },
   "outputs": [],
   "source": [
    "RMSE(lm, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This model has a higher R-square (0.897) and lower RMSE(1.66) than the previous model, which means that this model provides a better fit to the data than a model that only includes TV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret the **size coefficient**? For $1000 of TV/Radio/Newspaper ad spending, being a large market is associated with an average **increase** in Sales of 57.42 sales units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- To go much more in-depth on linear regression, read Chapter 3 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/), from which this lesson was adapted. Alternatively, watch the [related videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/) or read my [quick reference guide](http://www.dataschool.io/applying-and-interpreting-linear-regression/) to the key points in that chapter.\n",
    "- To learn more about Statsmodels and how to interpret the output, DataRobot has some decent posts on [simple linear regression](http://www.datarobot.com/blog/ordinary-least-squares-in-python/) and [multiple linear regression](http://www.datarobot.com/blog/multiple-regression-using-statsmodels/).\n",
    "- This [introduction to linear regression](http://people.duke.edu/~rnau/regintro.htm) is much more detailed and mathematically thorough, and includes lots of good advice.\n",
    "- This is a relatively quick post on the [assumptions of linear regression](http://pareonline.net/getvn.asp?n=2&v=8)\n",
    "- Learn more about p-value misconceptions [here](https://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values)\n",
    "- Watch [this](https://www.youtube.com/watch?v=jZEKAlo1E54) to learn about the types of outliers \n",
    "- Learn more about how to detect outliers [here](https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
